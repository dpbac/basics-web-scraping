{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#üìΩÔ∏èWeb-Scraping-Information-about-James-Bond's-Movies\" data-toc-modified-id=\"üìΩÔ∏èWeb-Scraping-Information-about-James-Bond's-Movies-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>üìΩÔ∏èWeb Scraping Information about James Bond's Movies</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1:-Inspecting-website\" data-toc-modified-id=\"Step-1:-Inspecting-website-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Step 1: Inspecting website</a></span></li><li><span><a href=\"#Step-2:-Access-Content-of-Website\" data-toc-modified-id=\"Step-2:-Access-Content-of-Website-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Step 2: Access Content of Website</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extracting-Information-from-Website\" data-toc-modified-id=\"Extracting-Information-from-Website-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Extracting Information from Website</a></span></li><li><span><a href=\"#Extracting-info-from-Table\" data-toc-modified-id=\"Extracting-info-from-Table-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Extracting info from Table</a></span></li></ul></li></ul></li><li><span><a href=\"#üé∂-Web-Scraping-Information-about-James-Bond's-Theme-Songs\" data-toc-modified-id=\"üé∂-Web-Scraping-Information-about-James-Bond's-Theme-Songs-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>üé∂ Web Scraping Information about James Bond's Theme Songs</a></span></li><li><span><a href=\"#üé∂-Web-Scraping-Lyrics:-How-to-Access-Information-within-Hyperlinks\" data-toc-modified-id=\"üé∂-Web-Scraping-Lyrics:-How-to-Access-Information-within-Hyperlinks-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>üé∂ Web Scraping Lyrics: How to Access Information within Hyperlinks</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO**\n",
    "\n",
    "- Review and add text in section on how to retrieve info from hyperlinks\n",
    "- Add missing songs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Edward Dennings said \"In God we trust; all other bring data.\", so bring us data. \n",
    "\n",
    "When data is not available through datasets or APIs, `web scraping` maybe be our last resource. It allows retrieving and parsing data stored on web pages across the Internet. It not only allow us retrieving data when we don't have it but also give us the opportunity to acquire additional data that might give that extra boost to our model. Therefore, obtaining data through `web scraping` is a valuable skill for any data scientist. \n",
    "\n",
    "In a `business point of view`, web scraping help us making informed business decision. It provide an opportunity to:\n",
    "\n",
    "* Know better competitors, their prices, services,\n",
    "* Know customers, their behavior, their needs, what they think of product(s)/service(s),\n",
    "* Stay well informed about partners,\n",
    "* Gather public opinion about a company in general, as well as of its or similar product(s)/service(s),\n",
    "* Obtain contact or other information of potential clients via social media and forums, so meaningfully resources can be directed towards this group of possible customers.\n",
    "\n",
    "and the list goes on....\n",
    "\n",
    "Also for `public/govermental organizations` web scraping can be very helpful. It might help gathering information from websites of different cities within an region about an important subject such as health, security, or environment. This data that sometimes are not easily collected across city agencies might be published by them on line. Therefore, this gives an opportunity to collect and analyze the data in order to extract beneficial insights to society.\n",
    "\n",
    "In addition, data obtained via web scraping can be used for personal purposes and for fun! For instances, it can help you find your new home, a new recipe, material for your hobby, or information about your favorite subject, artist, movie, music.... again imagination is the limit.\n",
    "\n",
    "Once you have your data, it is time to analyze and manipulate it using tools such as `pandas` and `numpy`.\n",
    "\n",
    "Here, to illustrate the use of web scraping we've chosen a subject that probably will please everybody (or most of you): Movies and Music! On top of it we will be an opportunity to pay our respect to the first Jams Bond, [Sir Thomas Sean Connery](https://www.imdb.com/name/nm0000125/bio) that left us October 31, 2020.\n",
    "\n",
    "Basically the following steps are taken:\n",
    "\n",
    "üìΩÔ∏è Extract information about all the movies from James Bond from a table at [List_of_James_Bond_films](https://en.wikipedia.org/wiki/List_of_James_Bond_films)\n",
    "\n",
    "üé∂ Extract information about all the James Bond's theme songs from a table at [Lijst_van_titelsongs_uit_de_James_Bondfilms](https://nl.wikipedia.org/wiki/Lijst_van_titelsongs_uit_de_James_Bondfilms) \n",
    "(\"Yes! Dutch site the structure of the table was much easier. So if you have an option go to the easy one  üòâ \")\n",
    "\n",
    "üé∂ Scrape lyrics of the theme songs that are not instrumental\n",
    "\n",
    "To accomplish this we need a basic knowledge of `HTML` which means its tree structure and that tags define the branches where the information we search are. Furthermore, we make use of two Python libraries:\n",
    "\n",
    "* [`requests`](https://requests.readthedocs.io/en/master/) which we allow us to get the webpage we want; and \n",
    "* [`Beautiful Soup`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) that parses the content of the webpage and allows us extracting tags from an HTML document.\n",
    "\n",
    "So let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìΩÔ∏èWeb Scraping Information about James Bond's Movies\n",
    "\n",
    "## Step 1: Inspecting website\n",
    "\n",
    "Every time we scrape a website we need to have an idea of its structure and where to find what we need.\n",
    "\n",
    "For this, no matter which browser we use, we can access its code by right clicking and choosing to access it source code, i.e., `view page` (Firefox) or `view page source` (Chrome and Microsoft Edge). If you need details of an specific element right click on it and choose `inspect element`(Firefox) or `inspect` (Chrome and Microsoft Edge), instead.\n",
    "\n",
    "Web pages use `HyperText Markup Language (HTML)` which is a markup language with its own syntax and rules. When a Web browser like Chrome or Firefox downloads a Web page, it reads the HTML to determine how to render it and display it to you.\n",
    "\n",
    "HTML consists of **tags**. Anything in between the opening and closing of a tag is the content of that tag. \n",
    "\n",
    "Some of elements that often encountered are:\n",
    "\n",
    "`<head>` : Contains metadata useful to the Web browser that's rendering the page and it is not visible to the user.\n",
    "\n",
    "`<body>` : Contains represents the content of an HTML document with which the user interacts.\n",
    "\n",
    "`<div>`: Section of the body.\n",
    "\n",
    "`<p>`: Used for paragraphs. \n",
    "\n",
    "`<a>` : Creates a hyperlink to web pages, files, email addresses, locations in the same page, or anything else a URL can address.\n",
    "\n",
    "For more definitions of elements check these links: [dev_mozilla](https://developer.mozilla.org/en-US/docs/Web/HTML/Element) or [w3s](https://www.w3schools.com/html/html_elements.asp)\n",
    "\n",
    "While inspecting the website source code you will notice that some tags contain attributes which provide special instructions for the contents contained within that tag. Specific html attributes names are followed by equal sign, followed by information which being passed to that attribute within that tag.\n",
    "\n",
    "For example:\n",
    "\n",
    "`<div id=\"contentSub\"></div>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this when repository become public\n",
    "\n",
    "<img src=\"https://github.com/dpbac/basics-web-scraping/blob/master/images/webpage_code_ex01.JPG\"/ width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/webpage_code_ex01.JPG\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Access Content of Website\n",
    "\n",
    "For this we need to :\n",
    "\n",
    "1. Access website using `requests`\n",
    "2. Parse content with `Beautiful Soup` so we can extract what we need within tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# importing packages\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "main_url = \"https://en.wikipedia.org/wiki/List_of_James_Bond_films\"\n",
    "\n",
    "# Send request and catch response: r\n",
    "response = requests.get(main_url)\n",
    "\n",
    "# get the content of the response\n",
    "content = response.content\n",
    "\n",
    "# parse webpage\n",
    "parser = BeautifulSoup(content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parse is a BeautifulSoup object, which represents the document as a nested data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to perform the same process for our 2 next tasks, so let's build a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_website(url):\n",
    "    \"\"\" \n",
    "    Parse content of a website\n",
    "    \n",
    "    Args:\n",
    "        url (str): url of the website of which we want to acess the content \n",
    "        \n",
    "    Return:\n",
    "        parser: representation of the document as a nested data structure.\n",
    "    \"\"\"\n",
    "    # Send request and catch response\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # get the content of the response\n",
    "    content = response.content\n",
    "\n",
    "    # parse webpage\n",
    "    parser = BeautifulSoup(content, \"lxml\")\n",
    "    \n",
    "    return parser  \n",
    "\n",
    "#     # Send request and catch response\n",
    "#     response = requests.get(main_url)\n",
    "\n",
    "#     # get the content of the response\n",
    "#     content = response.content\n",
    "\n",
    "#     # parse webpage\n",
    "#     parser = BeautifulSoup(content, \"lxml\")\n",
    "# #     parser = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "#     return parser\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Information from Website\n",
    "\n",
    "This part will depend on the structure of the website source code and of what you need as information from it.\n",
    "\n",
    "Before going to our target (table with information about James Bond Films) let's see how we can access some text of the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://en.wikipedia.org/wiki/List_of_James_Bond_films\"\n",
    "parser = parse_website(main_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the tree let's get the branches we want. To access the branches we use tags as attributes of parser. Therefore, to obtain the title of the webpage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = parser.title\n",
    "title = title.text\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Body` is the main branch of the HTML document where all elements such as paragraphs, hyperlinks are located. To access paragraphs we use tag `p`. If we use `find` the 1st paragraph is shown, if we use `find_all` we wil have acess to all paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body is with html element\n",
    "body = parser.body\n",
    "body;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first paragraph\n",
    "parser.body.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all paragraphs\n",
    "\n",
    "parser.body.find_all('p');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `find_all` returns a list and as one we can access an item using an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all paragraphs within the body of html\n",
    "list_paragraphs = parser.body.find_all('p')\n",
    "# extract the string within it\n",
    "list_paragraphs = [p.text for p in list_paragraphs]\n",
    "# show the first 2 paragraphs\n",
    "list_paragraphs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text of the first non-empty paragraphy\n",
    "print(parser.find_all('p')[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if you want all the text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_films = ' '.join(list_paragraphs).strip()\n",
    "# First 2000 characters\n",
    "print(text_films[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting info from Table\n",
    "\n",
    "You saw how to get some paragraphs, but what we really want as we said at the beginning is information about all movies and those are in the 1st table of the website.\n",
    "\n",
    "The table information can be found under tag `tbody`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(parser.find_all('tbody'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 tables in the website, but we are interested in the 1st one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parser.tbody;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal is to build a dataframe so I'll get the header (name of the columns/features) and the data (values for each feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parser.tbody.find_all('th', scope=\"col\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result is a list so we can use a list comprehension and apply some filtering to obtain the desired result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain column names within tag <th> with attribute col\n",
    "list_col_01 = parser.tbody.find_all('th', scope=\"col\")\n",
    "list_col_01 = [item.text.strip() for item in list_col_01 if ('Ref' not in item.text) & ('Total' not in item.text)]\n",
    "list_col_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add `Box office (millions)` and `Budget (millions)` before `Actual $` and `Adjusted 2005 $`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parser.tbody.find_all('th', class_=\"unsortable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain complement of column names at the attribute unsortable and some manipulation so we can have the correct names\n",
    "list_col_02 = parser.tbody.find_all('th', class_=\"unsortable\")\n",
    "list_col_02 = [item.text.strip().replace('[14]',\"\") for item in list_col_02 if ('Ref' not in item.text) & ('Total' not in item.text)]\n",
    "list_col_02=list_col_02*2\n",
    "list_col_02.sort()\n",
    "list_col_02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all together\n",
    "list_columns = [list_col_01[idx] if idx in range(len(list_col_01[:4])) else list_col_02[idx-4] +' '+ list_col_01[idx] for idx in range(len(list_col_01)) ]\n",
    "list_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the name of features to be used to build our dataframe, let's find the values for each feature. \n",
    "\n",
    "If we continue checking the content within `tbody` we will notice that `film titles` are found under tag `th` with attribute `row` while the rest of the information is found under `td` with same attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain title of the movies\n",
    "list_films = parser.tbody.find_all('th', scope = \"row\")\n",
    "list_films = [film.text.strip() for film in list_films]\n",
    "list_films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all other information about those movies\n",
    "list_info_films = [item.text.strip() for item in parser.tbody.find_all('td')]\n",
    "list_info_films = [list_info_films[idx] for idx in range(len(list_info_films)) if idx % 8 != 7]\n",
    "# showing the first 10 elements of the list\n",
    "list_info_films[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing information in list_info_films by features\n",
    "list_year_film = [list_info_films[idx] for idx in range(len(list_info_films)) if idx % 7 == 0 ]\n",
    "list_actor = [list_info_films[idx] for idx in range(len(list_info_films)) if idx % 7 == 1 ]\n",
    "list_director = [list_info_films[idx] for idx in range(len(list_info_films)) if idx % 7 == 2 ]\n",
    "list_box_office_actual = [list_info_films[idx] for idx in range(len(list_info_films)) if idx % 7 == 3 ]\n",
    "list_box_office_adj_2005 = [list_info_films[idx] for idx in range(len(list_info_films)) if idx % 7 == 4 ]\n",
    "list_budget_actual = [list_info_films[idx] for idx in range(len(list_info_films)) if idx % 7 == 5 ]\n",
    "list_budget_adj_2005 = [list_info_films[idx] for idx in range(len(list_info_films)) if idx % 7 == 6 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists_films = [list_films, list_year_film, list_actor, list_director, list_box_office_actual, list_box_office_adj_2005, \n",
    "                 list_budget_actual, list_budget_adj_2005]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary for our dataframe\n",
    "dict_films = {list_columns[idx]:list_of_lists_films[idx] for idx in range(len(list_columns))}\n",
    "# showing 2 items of the dictionary\n",
    "dict(list(dict_films.items())[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = pd.DataFrame(dict_films)\n",
    "df_films.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll rename column film to `Film Title` so we can use it when merging dataframes with film and music information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films.rename(columns = {'Title': 'Film Title'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé∂ Web Scraping Information about James Bond's Theme Songs\n",
    "\n",
    "For this task I've chosen the Dutch Wikipedia website because the structure of the table is simpler to extract the information we want and the information there is mostly in English.\n",
    "\n",
    "Let's start by using our function to parse the content of the website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this I checked first: https://en.wikipedia.org/wiki/James_Bond_music\n",
    "\n",
    "main_url = \"https://nl.wikipedia.org/wiki/Lijst_van_titelsongs_uit_de_James_Bondfilms\"\n",
    "\n",
    "parser = parse_website(main_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the information we are looking for is in the first table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.find('tbody');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of columns \n",
    "list_columns = parser.tbody.find_all('th')\n",
    "list_columns = [item.text.strip() for item in list_columns]\n",
    "list_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or in English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = ['Theme Song', 'Performer', 'Film Title', 'Year', 'Composer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time obtaining the header of our data frame was pretty direct. Indeed, we could simply type the list, especially since we needed to translate it. However, it is good to show how different it was from the previous section. Therefore, how you retrieve the information you get depends on the structure of the website.\n",
    "\n",
    "We have now the names of our 5 columns. Following, we will build the content of our table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information about Jame Bond's theme songs\n",
    "list_table_songs = parser.tbody.find_all('td')\n",
    "list_table_songs = [item.text.strip() for item in list_table_songs]\n",
    "# showing the 1st 10 items of the list\n",
    "list_table_songs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<td>` is a html element that defines a cell of a table that contains data. As we can notice above every 5 rows (cells of the table) contains respectively, `Theme Song`, `Performer`, `Film Title`, `Year`, `Composer`. Let's use this to build our data frame with all theme songs of the James Bond film series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting information by feature\n",
    "list_title_songs = [list_table_songs[idx] for idx in range(len(list_table_songs)) if idx % 5 == 0 ]\n",
    "list_performers = [list_table_songs[idx] for idx in range(len(list_table_songs)) if idx % 5 == 1 ]\n",
    "list_films = [list_table_songs[idx] for idx in range(len(list_table_songs)) if idx % 5 == 2 ]\n",
    "list_years = [list_table_songs[idx] for idx in range(len(list_table_songs)) if idx % 5 == 3 ]\n",
    "list_composers = [list_table_songs[idx] for idx in range(len(list_table_songs)) if idx % 5 == 4 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists_songs = [list_title_songs, list_performers, list_films, list_years, list_composers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_songs = {list_columns[idx]:list_of_lists_songs[idx] for idx in range(len(list_columns))}\n",
    "\n",
    "# showing 2 items of the dictionary\n",
    "dict(list(dict_songs.items())[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs = pd.DataFrame(dict_songs)\n",
    "df_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good, right? In what concern web scraping our job is done but as data scientists we need to do our best to have clean data and the most complete and right information. No trash in, trash out! So, there are just little things we need to fix.\n",
    "\n",
    "First, the first movie of the James Bond franchise, `Dr. No`, has two themes. However, we have information only about the performer of the 1st theme. In addition, formally [Monty Norman](https://en.wikipedia.org/wiki/James_Bond_Theme) is the composer of both James Bond theme and Kingston Calypso.\n",
    "\n",
    "Second, in some items we find `o.l.v` that means in Dutch `onder leiding van` which we can translate to `led by`.\n",
    "\n",
    "At last, the `Year` of the last film is 2021 as in the films table. The film was supposed to be released in 2020 but due to COVID it will be released in 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs['Theme Song'].iloc[0] =\"James Bond Theme / Kingston Calypso\"\n",
    "df_songs['Composer'].iloc[0] = 'Monty Norman / Byron Lee and the Dragonaires'\n",
    "\n",
    "# replace 'o.l.v.'' by 'led by'\n",
    "df_songs['Performer'] = df_songs['Performer'].apply(lambda x : x.replace('o.l.v.','led by'))\n",
    "\n",
    "# correct year of last move\n",
    "df_songs['Year'].iloc[24] = '2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put all together let's check if columns `Film Title` in both films and songs dataframe are equal. Remember that the 1st movie has 2 entries in `df_songs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['Film Title'].equals(df_songs['Film Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films_songs = df_films.merge(df_songs, on = ['Film Title', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films_songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have you data all together you can answer some questions. For instances:\n",
    "\n",
    "‚ùî **Which actor performed James Bond more times?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(y=df_films_songs['Bond actor'], order = df_films_songs['Bond actor'].value_counts().index)\n",
    "plt.title(\"Actors by Order of How Many Times he Performed 'James Bond'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_films_songs['Bond actor'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `Roger Moore` performed the 007 agente more times, followed by `Sean Connery`. If `Daniel Craig` goes on for 2 more movies he will replace Roger Moore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùî **What was the Box Office and Budget?**\n",
    "\n",
    "For this we need some cleaning first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films_songs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Features Box office (millions) Actual $`, `Box office (millions) Adjusted 2005 $`, `Budget (millions) Actual $`,`Budget (millions) Adjusted 2005 $` are `object` type when they should be `float`. This happened because of `TBD` (meaning To Be Defined) and the values given as intervals in indexes 22 and 23 of `Budget (millions) Actual $` and `Budget (millions) Adjusted 2005 $`.\n",
    "\n",
    "First, let's replace `TBD` by 0.00 since the film will be release in 2021.\n",
    "\n",
    "Second, let's replace the interval of values by it's mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films_songs = df_films_songs.replace('TBD',0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(interval_str):\n",
    "    \"\"\" Calculate mean of a and b where a and b are in the expression `a-b` (string) \"\"\"\n",
    "    \n",
    "    interval_str = interval_str.replace('[b]','')\n",
    "    \n",
    "    a = float(interval_str.split('‚Äì')[0])\n",
    "    b = float(interval_str.split('‚Äì')[1])\n",
    "    \n",
    "    return round((a + b/2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films_songs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(22,24):\n",
    "    \n",
    "    df_films_songs.loc[idx,'Budget (millions) Actual $'] = calculate_mean(df_films_songs.loc[idx,'Budget (millions) Actual $'])\n",
    "    df_films_songs.loc[idx,'Budget (millions) Adjusted 2005 $'] = calculate_mean(df_films_songs.loc[idx,'Budget (millions) Adjusted 2005 $'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Box office (millions) Actual $','Box office (millions) Adjusted 2005 $', 'Budget (millions) Actual $',\n",
    "       'Budget (millions) Adjusted 2005 $']:\n",
    "    \n",
    "    df_films_songs[col] = df_films_songs[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films_songs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15, 15))\n",
    "tidy = df_films_songs.melt(id_vars='Film Title',  value_vars=['Box office (millions) Actual $',\n",
    "       'Box office (millions) Adjusted 2005 $', 'Budget (millions) Actual $',\n",
    "       'Budget (millions) Adjusted 2005 $']).rename(columns=str.title)\n",
    "sns.barplot(y='Film Title', x='Value', hue='Variable', data=tidy, ax=ax1)\n",
    "plt.title(\"Compare Box Office and Budget of Bond's films until 2008\", size=16)\n",
    "plt.legend(loc = \"center right\", title = \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking only actual values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15, 15))\n",
    "tidy = df_films_songs.melt(id_vars='Film Title',  value_vars=['Box office (millions) Actual $', 'Budget (millions) Actual $']).rename(columns=str.title)\n",
    "sns.barplot(y='Film Title', x='Value', hue='Variable', data=tidy, ax=ax1)\n",
    "plt.title(\"Compare Box Office and Budget of Bond's films until 2008\", size=16)\n",
    "plt.legend(loc = \"center right\", title = \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that is pretty profitable, right? This video shows how the film industry make money and how taking Box Office as proxy for profit can be misleading https://www.youtube.com/watch?v=jRuc7YgZ_n8&feature=emb_logo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùî **Is there any performer that performed songs more than once?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films_songs['Performer'].value_counts()[df_films_songs['Performer'].value_counts().values > 1].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which songs and in which years she song?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films_songs[['Theme Song','Year']][df_films_songs['Performer']=='Shirley Bassey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé∂ Web Scraping Lyrics: How to Access Information within Hyperlinks\n",
    "\n",
    "To show how to scrape webpages within a webpage let's obtain lyrics of James Bond's theme songs.\n",
    "\n",
    "Here we will build a dataframe with song titles, performers, and lyrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://www.stlyrics.com/b/bestofbondjamesbond.htm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = parse_website(main_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_hyperlinks(main_url):\n",
    "    \"\"\" \n",
    "    Find hyperlinks in 'main_url' \n",
    "    \n",
    "    Args:\n",
    "        main_url: Main webpage containing hyperlinks\n",
    "        \n",
    "    Return:\n",
    "        list of url: list of hyperlinks from main_url\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all 'a' tags (which define hyperlinks): a_tags\n",
    "\n",
    "    a_tags = parser.find_all('a')\n",
    "\n",
    "    # Create a list with hyperlinks found\n",
    "\n",
    "    list_links = [link.get('href') for link in a_tags]\n",
    "\n",
    "    # Remove none values if there is some\n",
    "    # Remove none values if there is some\n",
    "    \n",
    "    list_links = list(filter(None, list_links)) \n",
    "    \n",
    "    return list_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_links = retrieve_hyperlinks(main_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_links = list(set(list_links))\n",
    "\n",
    "print('\\n Number of links before filtering:', len(list_links))\n",
    "list_links[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_links = [link for link in list_links if 'bestofbondjamesbond' in link]\n",
    "print('\\n Number of links after filtering:', len(list_links))\n",
    "list_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_urls = [\"https://www.stlyrics.com\"+link for link in list_links]\n",
    "complete_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lyric_url = complete_urls[0]\n",
    "\n",
    "# r_lyric = requests.get(lyric_url)\n",
    "    \n",
    "# # obtain text with html containt of the url\n",
    "# html_doc_lyric = r_lyric.content\n",
    "    \n",
    "# # making html easier to read\n",
    "# soup_lyric = BeautifulSoup(html_doc_lyric,\"lxml\")\n",
    "\n",
    "soup_lyric = parse_website(lyric_url)\n",
    "\n",
    "lyric_list = soup_lyric.find_all('div', class_=\"highlight\")\n",
    "    \n",
    "lyric_list=[item.text.strip() for item in lyric_list ]\n",
    "    \n",
    "# Remove none values if there is some\n",
    "lyric_list = list(filter(None, lyric_list)) \n",
    "\n",
    "print('\\n'.join(lyric_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lyric_from_url(lyric_url):\n",
    "    \"\"\" \n",
    "    Extract lyrics after prettify beautiful soup from /www.stlyrics.com\n",
    "    \n",
    "    Args: \n",
    "        lyric_url: url for lyric website\n",
    "        \n",
    "    Return:\n",
    "        text of lyrics\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # send a http request\n",
    "    r_lyric = requests.get(lyric_url)\n",
    "    \n",
    "    # obtain text with html containt of the url\n",
    "    html_doc_lyric = r_lyric.text\n",
    "    \n",
    "    # making html easier to read\n",
    "    soup_lyric = BeautifulSoup(html_doc_lyric,\"lxml\")\n",
    "\n",
    "    lyric_list = soup_lyric.find_all('div', class_=\"highlight\")\n",
    "    \n",
    "    lyric_list=[item.text.strip() for item in lyric_list ]\n",
    "    # Remove none values if there is some\n",
    "    \n",
    "    lyric_list = list(filter(None, lyric_list)) \n",
    "\n",
    "    return ' '.join(lyric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_lyrics = []\n",
    "list_links = []\n",
    "\n",
    "for link in complete_urls:\n",
    "    list_lyrics.append(extract_lyric_from_url(link))\n",
    "    list_links.append(link.split('/')[-1].replace('.htm',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(list_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links = pd.DataFrame({'links':list_links, 'lyrics': list_lyrics})\n",
    "df_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before merging we need to split the first row which contain information about 2 theme songs. For this I'll append to the dataframe 2 new rows with information about each of the songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Appending two new rows with updated information\n",
    "\n",
    "df_songs = df_songs.append({'Theme Song':\"James Bond Theme\", 'Performer':'Orkest led by John Barry', \n",
    "                            'Film Title':'Dr. No', 'Year':'1962', 'Composer': 'Monty Norman'}, ignore_index=True)\n",
    "df_songs = df_songs.append({'Theme Song': \"Kingston Calypso (a.k.a 'Three Blind Mice')\", 'Performer':\"Byron Lee and the Dragonaires\",\n",
    "                            'Film Title':'Dr. No', 'Year':'1962', 'Composer': 'Monty Norman'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then drop the old one and re-organize the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the incomplete info about Dr. No \n",
    "df_songs.drop_duplicates(subset=[\"Film Title\",\"Performer\"], keep='last', inplace=True)\n",
    "# re-organize dataframe by Year\n",
    "df_songs.sort_values('Year', inplace=True)\n",
    "# reset index\n",
    "df_songs.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lyrics = df_songs.copy()\n",
    "df_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['links'] = df_lyrics['Theme Song'].apply(lambda x: x.lower().replace(' ','').replace(\"'\",''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When merging we choose `outer` on how to merge so we can see clearer if there is some information missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_lyrics = df_lyrics.merge(df_links, on='links', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that in column `lyrics` we have four `NaN` and one empty cell. The empty cell for the `James Bond Theme` is expected since this is an instrumental songs.\n",
    "\n",
    "The other four are lyrics that are missing. This because the website we used are based in a collection of themes that goes until 2008.\n",
    "\n",
    "We also notice that the last row have `NaN` for `Theme Song`, `Performer`, `Film Title`, `Year`, and `Composer`. But we know the title of the song by the link: `We have all the time in the world`.\n",
    "\n",
    "A litle googleled shows that this [James Bond Theme](https://en.wikipedia.org/wiki/We_Have_All_the_Time_in_the_World) performed by Louis Amstrong was the second theme of `On Her Majesty's Secret Service (1969)` and was composed by Hal David and John Barry. In addition, it says that the other theme `On Her Majesty's Secret Service` is instrumental. Therefore, it is a mistake in the website. In fact, when checking the lyrics there are from 1985! A band called `Orchestral manoeuvres in the dark` and the song is called `Secret`.\n",
    "\n",
    "Therefore, to make things right we :\n",
    "\n",
    "1. Remove lyrics from song theme `On Her Majesty's Secret Service`\n",
    "2. We add the missing information of the second (non-instrumental) theme of `On Her Majesty's Secret Service`\n",
    "2. We add lyrics to:\n",
    "    * Kingston Calypso a.k.a Three Blind Mice (1962)\n",
    "    * Skyfall (2012)\n",
    "    * Writing's On The Wall (2015)\n",
    "    * No Time to Die (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lyrics of \"On Her Majesty's Secret Service\"\n",
    "\n",
    "df_lyrics['lyrics'][df_lyrics['Theme Song']==\"On Her Majesty's Secret Service\"]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add info about theme song 'We have all the time in the world'\n",
    "\n",
    "df_lyrics = df_lyrics.append({'Theme Song': \"We Have All The Time in the World\", \n",
    "                              'Performer':\"Louis Amstrong\",\n",
    "                              'Film Title':\"On Her Majesty's Secret Service\", 'Year':'1969', \n",
    "                              'Composer': 'John Barry & Hal David', \n",
    "                              'links':'wehaveallthetimeintheworld',\n",
    "                              'lyrics':df_lyrics['lyrics'][df_lyrics['links']=='wehaveallthetimeintheworld'].values[0]}, \n",
    "                             ignore_index=True)\n",
    "\n",
    "df_lyrics.drop_duplicates('links', keep='last', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three out the 4 lyrics can be found in the same website (https://www.songteksten.nl/). Let's start by `Kingston Calypso a.k.a Three Blind Mice` that is found in a different website (https://www.flashlyrics.com/lyrics/monty-norman/kingston-calypso-75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calypso_url = \"https://www.flashlyrics.com/lyrics/monty-norman/kingston-calypso-75\"\n",
    "r_calypso = requests.get(calypso_url)\n",
    "\n",
    "# obtain text with html containt of the url\n",
    "html_doc_calypso = r_calypso.content\n",
    "\n",
    "# making html easier to read\n",
    "soup_calypso = BeautifulSoup(html_doc_calypso,\"lxml\")\n",
    "\n",
    "soup_calypso\n",
    "\n",
    "lyric_list = soup_calypso.find_all('div', class_=\"main-panel-content\")[0].find_all('span')\n",
    "\n",
    "lyric_list=[item.text.strip() for item in lyric_list ]\n",
    "\n",
    "# Remove none values if there is some\n",
    "lyric_list = list(filter(None, lyric_list)) \n",
    "\n",
    "print('\\n'.join(lyric_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "songtekten_url = \"https://songteksten.net/lyric/5056/94896/adele/skyfall.html\"\n",
    "r_songtekten = requests.get(songtekten_url)\n",
    "\n",
    "# obtain text with html containt of the url\n",
    "html_doc_songtekten = r_songtekten.content\n",
    "\n",
    "# making html easier to read\n",
    "soup_songteksten = BeautifulSoup(html_doc_songtekten,\"lxml\")\n",
    "\n",
    "lyric_list = soup_songteksten.find_all('div', class_=\"col-sm-7 content-left\")\n",
    "\n",
    "lyric_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the text of the lyrics is between `line breaks`, i.e., <\\br> tags. This [link](https://stackoverflow.com/questions/5275359/using-beautifulsoup-to-extract-text-between-line-breaks-e-g-br-tags) points a nice solution using a `childGenerator` from BeautifulSoup.\n",
    "\n",
    "We combined this solution with some filtering in a list comprehension and voil√°!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_list = []\n",
    "for a in lyric_list[0].childGenerator():\n",
    "    lyrics_list.append(a)\n",
    "    \n",
    "lyrics_list = [str(a).strip() for a in lyric_list[0].childGenerator() if ('<h1' not in str(a)) and ('<div' not in str(a)) and ('<br/>' not in str(a))]\n",
    "\n",
    "# Remove none values if there is some\n",
    "lyrics_list = list(filter(None, lyrics_list)) \n",
    "\n",
    "lyrics = '\\n'.join(lyrics_list)\n",
    "print(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lyrics_songtekstennl(songteksten_url):\n",
    "    \"\"\" \"\"\"\n",
    "    r_songteksten = requests.get(songteksten_url)\n",
    "\n",
    "    # obtain text with html containt of the url\n",
    "    html_doc_songteksten = r_songteksten.content\n",
    "\n",
    "    # making html easier to read\n",
    "    soup_songteksten = BeautifulSoup(html_doc_songtekten,\"lxml\")\n",
    "    \n",
    "    lyric_list = soup_songteksten.find_all('div', class_=\"col-sm-7 content-left\")\n",
    "\n",
    "    lyrics_list = []\n",
    "    for a in lyric_list[0].childGenerator():\n",
    "        lyrics_list.append(a)\n",
    "    \n",
    "    lyrics_list = [str(a).strip() for a in lyric_list[0].childGenerator() if ('<h1' not in str(a)) and ('<div' not in str(a)) and ('<br/>' not in str(a))]\n",
    "\n",
    "    # Remove none values if there is some\n",
    "    lyrics_list = list(filter(None, lyrics_list)) \n",
    "\n",
    "    lyrics = '\\n'.join(lyrics_list)\n",
    "    print(lyrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "songteksten_url = \"https://www.songteksten.nl/songteksten/362930/adele/skyfall.htm\"\n",
    "extract_lyrics_songtekstennl(songteksten_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_songteksten = parse_website(songteksten_url)\n",
    "lyric_list = soup_songteksten.find_all('div', class_=\"col-sm-7 content-left\")\n",
    "\n",
    "lyric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.split('</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lyric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_list = soup_calypso.find_all('div', class_=\"main-panel-content\")[0].find_all('span')\n",
    "\n",
    "lyric_list=[item.text.strip() for item in lyric_list ]\n",
    "\n",
    "# Remove none values if there is some\n",
    "# lyric_list = list(filter(None, lyric_list)) \n",
    "\n",
    "print('\\n'.join(lyric_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop columns links\n",
    "\n",
    "df_lyrics.drop('links', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO CONTINUE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include information about https://en.wikipedia.org/wiki/We_Have_All_the_Time_in_the_World\n",
    "\n",
    "1969 Bond film On Her Majesty's Secret Service,\n",
    "\n",
    "https://www.songteksten.nl/songteksten/365987/louis-armstrong/we-have-all-the-time-in-the-world.htm\n",
    "\n",
    "Adele (2012) : https://www.songteksten.nl/songteksten/362930/adele/skyfall.htm\n",
    "\n",
    "Sam Smith (2015) - Spectre - https://www.songteksten.nl/artiest/131949/sam-smith.htm\n",
    "\n",
    "Billie Eilish (2021) - No time to day - https://www.songteksten.nl/songteksten/1130189/billie-eilish/no-time-to-die.htm\n",
    "\n",
    "https://www.flashlyrics.com/lyrics/monty-norman/kingston-calypso-75\n",
    "\n",
    "\n",
    "Add extra songs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['lyrics'].iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs = df_songs.append({'Theme Song': \"Kingston Calypso (a.k.a 'Three Blind Mice')\", 'Performer':\"Byron Lee and the Dragonaires\",\n",
    "                            'Film Title':'Dr. No', 'Year':'1962', 'Composer': 'Monty Norman'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lyrics.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lyrics"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def parse_pages(self, response):\n",
    "    # Create a SelectorList of the course titles text\n",
    "    crs_title = response.xpath('//h1[contains(@class,\"title\")]/text()')\n",
    "    # Extract the text and strip it clean\n",
    "    crs_title_ext = crs_title.extract_first().strip()\n",
    "    # Create a SelectorList of course descriptions text\n",
    "    crs_descr = response.css('p.course__description::text')\n",
    "    # Extract the text and strip it clean\n",
    "    crs_descr_ext = crs_descr.extract_first().strip()\n",
    "    # Fill in the dictionary\n",
    "    dc_dict[crs_title_ext] = crs_descr_ext\n",
    "\n",
    "# Initialize the dictionary **outside** of the Spider class\n",
    "dc_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "217.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
